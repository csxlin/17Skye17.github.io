---
title: 'CVPR2019 Paper Reading'
date: 2019-06-21
permalink: /posts/2012/08/blog-post-9/
tags:
  - CVPR 2019
---

The most suitable approach to handle disappointment is reading papers. :):disappointed:

CVPR2019 Papers:

**Oral:**

:star:  scan

:star::star:  read carefully 

:star::star::star:   read carefully & recommend

+ **Learning Video Representations from Correspondence Proposals.** :star::star::star:

**abstract**: building long-range dependencies, sounds like the same spirit as non-local, attention etc.

**motivation**: idea gains from deep learning on point clouds and point motion.搜了下这几位作者之前是做３ｄ的，正好把相关的idea迁移到视频上。与这篇文章相关的影子：GCN,non-local等。

**interesting points**: 总结了什么是好的视频表示

1. Corresponding positions have similar visual or semantic features.

2. Corresponding positions can span arbitrarily long ranges, spatially or temporally.

3. Potential correspondence positions in other frames are small in percentage.

