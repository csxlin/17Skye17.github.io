---
title: 'GCN'
date: 2019-06-29
permalink: /posts/2012/08/blog-post-17/
tags:
  - CVPR 2019
  - Unsupervised Dommain Adaptation
  - GCN
---

图卷积神经网络学习一下...

+ **GCAN: Graph Convolutional Adversarial Network for Unsupervised Domain Adaptation** (中科院张天柱组)

解决的问题：数据结构对齐，domain对齐和类别中心对齐，学习domain不变性和语义表示，减少domain差异（与之前的几篇oral一样还是关注class-level的对齐）

提出的方法：end-to-end Graph Convolutional Adversarial Network(GCAN)

domain对齐：GAN
class centroid对齐：伪标注的目标特征和标注了的源特征计算class centroid alignment loss。

方法细节：GCAN的loss包括四个部分：

1. 分类loss: 多类交叉熵损失

2. Domain Alignment Loss:GAN loss

3. structure-aware triplet los:采用GCN的主要目的，先用一些现有的2D CNN提取特征，每个sample的特征表示一个node。为了构建邻接矩阵，提出了Data 
Structure Analyzer(DSA)直接把原始的一个batch的数据放到DSA network（就是一个卷积神经网络），生成结构分数，然后由结构分数乘以结构分数的转置得到
邻接矩阵（一个相似性矩阵）。结构分数可以进一步采用triplet loss来约束，从source domain中随机采样一个sample a和一个同类别的sample p，以及一个不同类别的sample n，那么训练目标可以设定为使
sample a和sample p的结构分数越接近越好，sample a和sample n的结构分数差异越大越好。 

GCN相当于给原来特征上加了数据相似性信息，如果用其他的聚类方法应该也能有相同效果（例如原型神经网络），为什么用两个CNN来产生相似性矩阵和特征，不用一个CNN？

4. 类别对齐loss:参考了ICML2018文献Learning semantic representations for unsupervised domain adaptation中的方法，首先采用一个分类器给
数据打上伪标签，然后计算source domain和target domain每个类别的中心之间的L2距离作为loss。


实验结果在Office-31数据集上平均准确率达到80.6%，在ImageCLEF-DA数据集上平均准确率达到80.9%，两个数据集cross-domain的平均准确率达到51.05%。
整篇看下来方法主要是组合的部分比较多，模型训练复杂度比较高，感觉GCN的使用不是很必要？
