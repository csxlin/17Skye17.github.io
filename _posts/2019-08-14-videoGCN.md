---
title: 'Video+GCN'
date: 2019-08-07
permalink: /posts/2012/08/blog-post-21/
tags:
  - Action Recognition
  - GCN
---

**(ECCV2018)Videos as Space-Time Region Graphs** (Xiaolong Wang)

用GCN来建模视频动作识别：　

1.建模相关物体长范围的相似性关联；

2.建模相邻物体的时空关联。

大致方法：将输入的视频帧当做一个space-time region graph，其中每个node表示视频中的ROI，node之间有两种edge:１.外观相似度; 2.时空近似。
总的来说是在原始的i3d特征之上，再融合了一个object clue，用GCN编码object clue，总体上是global+local特征。

重点：编码object，用了一个similarity graph和一个spatial-temporal graph。
其中similarity graph的edge用一个邻接矩阵表示，任意i和j物体之间的相似性计算由object proposal feature之间的亲和性表示（将各自的feature先做embedding再相乘）。再对矩阵的每一行作softmax进行归一化。

spatial-temporal graph是一个DAG（双向），用一个邻接矩阵表示边权。边权由两个object bbox的IoUs表示，然后所有的边权进行l1 normalization。

构造好graph之后，在graph作卷积操作进行推理，具体操作是分为两个branch（主要应为similarity grpah中要学习的两个embedding矩阵参数，DAG中没有学习参数，如果直接把这三个graph直接先concatenate，再share图卷积的训练参数，会导致训练不稳定结果变差）：

1. similarity graph单独作为一个branch，与输入的Nxd维i3d特征相乘再乘以一个dxd维的模型参数矩阵。

2. DAG作为一个branch，front graph和back graph的邻接矩阵先单独进行如1的矩阵乘操作再concatenate。

最后把两个branch输出加上一个i3d特征的残差得到最终的feature。

训练步骤比较繁琐：

1.先



问题：总的object的个数N应该是多少？（一个数据集中可能object有成千上万个，这样在图卷积操作时的邻接矩阵和输入特征矩阵的维度非常大10,000 x 10,000）
