---
title: 'CVPR2019 Paper Reading(Part 2)'
date: 2019-06-21
permalink: /posts/2012/08/blog-post-10/
tags:
  - CVPR 2019
---

继续扫文...

+ **Semantics Distangling for Text-to-Image Generation**(王晓刚商汤组) :star::star::star:

提出SD-GAN，大致架构是siamese＋sequential stacked generatror-discriminator modules（其组里之前１７年两篇工作都用了），
用contrastive loss，目的是缩小同一图片两个不同描述生成的图片差异，增大不同图片的差异。

其组里做的AttnGAN和StackGAN处理细粒度的text2img比较成功，但是处理文字表达的多样性还是一个challenge。

**Text Encoder**: 用一个BiLSTM，取最后一个hidden layer的输出作为text的feature vector

**Contrastive loss**: 在普通的contrastive loss上改了一个当y=1时，让d尽量接近alpha而不是０，防止模式坍缩

**Semantic-Conditioned Batch  Normalization(SCBN)**:　在原始的Conditional Batch Norm(CBN ICLR2017)上加入了sentence cues和word cues，
sentence cues加了一个将输入进行MLP变换的操作，word cues将word和视觉特征之间通过MLP关联，得到的semantic feature vector输入到原始的CBN中。

**Experimental Results**:实验结果inception score在CUB和MS-COCO上大幅超过了其组里之前的AttnGAN和StackGAN。实验结果表明SCBN植入到其他网络例如
AttnGAN中能够带来明显的性能增益。

+ **Inserting Videos into Videos**(Ming-Husan Yang组)

看起来很有意思的一篇文章，将一个视频中的物体植入到另一个视频当中，直观效果不错，首先能够想到的方法是先做分割。（又是一个新坑？...）

具体方法感兴趣再看，实验结果通过YOLOv3看能否检测到合成的视频中被正确植入了物体，用到一些person re-id的数据集，结果表明该提出的方法precision和recall
值高出现有算法10%左右，合成效果明显优于现有的分割算法DeepLabv3+（tensorflow group）。

+ **STEP: Spatio-Temporal Progressive Learning for Video Action Detection** (Larry Davis组)

