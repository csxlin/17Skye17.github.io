---
title: 'CVPR2019 Paper Reading(Domain Adaptation)'
date: 2019-06-25
permalink: /posts/2012/08/blog-post-14/
tags:
  - CVPR 2019
  - Unsupervised Domain Adaptation
---

赶热点 Domain adaptation... 今年oral做UDA的真多...

+ **Taking A Closer Look at Domain Shift: Category-level Adversaries for Semantics Consistent Domain Adaptation** (郑良，于俊清)

今年华科的oral不少，很感兴趣的一篇文章，方法不复杂且很有insight，这篇主要follow了2018年CVPR spotlight *Learning to adapt structured output space for semantic segmentation*(Ming-Hsuan Yang组)

解决的问题：　目前domain adaptation的方法采用的是global adaptation可能导致一些本来对齐的类别被错误地映射。

idea:　减小类别对齐特征的对抗loss权重，增加没有对齐的类别的对抗loss权重。

目前的方法：1.对齐不同domain的feature，减小两个domain的散度降低目标domain的错误上界；

2.生成对抗：生声器生成特征让判别器难以分辨特征属于哪个domain

目前方法的问题：只考虑全局边界分布，不考虑局部联合分布的偏移。

方法：基于co-training，在原本的adversarial loss中加入weight discrepancy loss和在self-adaptive adversarial loss中加入一个类别的cosine distance矩阵（两个classifier输出的predictions之间的相似性矩阵）。

总的优化目标是：分割的loss（多类交叉熵损失）+　weight discrepancy loss + category-level adversatial loss

其中weight discrepancy loss是两个分类器当中卷积核参数经过flatten和concatenate之后的cosine距离，多类交叉熵损失的输入是将两个分类器输出的predictions加和（ensemble）。

t-SNE可视化特征分布来看，使用CLAN的特征边界更清晰，大多数类别的分割效果比去年TAN好一些。


+ **Transferrable Prototypical Networks for Unsupervised Domain Adaptation** (梅涛，姚霆)

TPN首先将目标样本匹配到source domain当中距离最近的原型，优化方案：端到端训练，最小化source-only, target-only和source-target数据的distance,以及每一对原型的输出分数分布的KL散度。

现有的方法：
1.对齐source domain和target domain的数据分布

2.最小化domain不变性通过最小化shift例如：相关性距离，最大均值差异

原型网络本质上是将数据在embedding space中的特征聚类，所以主要的一个adaptation的方法是：用原型表示每一个每一个类别分布，匹配embedding space当中每个类别的原型，embedding space在不同domain的数据上学习得到。

这篇文章考虑了general-purpose adaptation和task-specific adaptation。提出了Transferrable Prototypical Networks(TPN)，理想情况下可以将样本非线性地映射到embedding space, 不同domain的表示不同。具体来说TPN计算每一个没有标签的样本到每一个有标签的原型（cluster）的距离，然后将最近的原型的标签给没有标签的样本作为pseudo label。




Idea: 不在整个图片上计算原型网络，而在detector检测出来的region proposal上计算原型距离，并且可以考虑co-training的形式，将detector的mask位置考虑进去。




co-training学习detector在两个domain的bbox位置，Position Loss

学习两个bbox中的子图的差异，Adversarial Loss

idea: 当前在目标检测的task-specific  adaptation的方法当中没有考虑空间位置和domain adaptation的关系。

1. domain adaptation时有一些信息是冗余的，不需要对整个图片的representation进行操作；

TPN训练：最小化source domain上的分类损失+2个adaptation项。

TPN inference：每个原型作为先验进行计算，测试样本先映射到embedding space然后比较与每一个原型的距离，最后由softmax得到类别的概率分布。
