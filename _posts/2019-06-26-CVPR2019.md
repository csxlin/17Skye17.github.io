---
title: 'CVPR2019 Paper Reading(Domain Adaptation 2)'
date: 2019-06-26
permalink: /posts/2012/08/blog-post-15/
tags:
  - CVPR 2019
  - Domain Adaptation
---

继续扫文...

+ **AdaGraph: Unifying Predictive and Continuous Domain Adaptation through Graphs.** (几个意大利作者，Barbara Caputo, Elisa Ricci)

解决的问题： predictive domain adaptation，跟前面两篇侧重点不一样。

Introduction:介绍领域漂移问题（domain shift），在source domain的数据上训练过的分类器表现良好，而在target domain上表现很差。目前Predictive Domain Adaptatio(PDA)方法在训练的时候用到了target domain的数据和标签，本文提出的方法训练时只用到source domain的标签和辅助信息，不用target domain的*数据*和*标签*，这个设定比之前的UDA更难，可能模型要学到不同domain之间数据的一些属性。

方法描述：采用graph来表示不同domain之间的关联,即node表示domain,edge表示不同domain之间关联，与此前的原型神经网络异曲同工，聚类－> graph，　category-level关联－>domain关联。

目前不太了解meta-data的设定，感兴趣再看。

+ **Classification-Reconstruction Learning for Open-Set Recognition** (东京大学)

目前方法的问题：在已知类别上监督训练学习表示，导致难以区分未知的类别和已知的类别。

方法：联合输入数据的分类和重建，提出Classification-Reconstruction learning for Open-Set Recognition(CROSR)，以及一个Deep Hierarchical Reconstruction Nets(DHRNets)。

Contributions:1.第一个开放集识别当中深度重建表示的作用；

２．提出了一个基于DHRNets的CROSR framework，改进了LadderNet的自编码器结构。

方法主要改进：１．在原始的Openmax上加了一个重建项，每个类别的概率分布不仅仅考虑最后全连接层输出的logits，而考虑logits和重建的decoder网络输入的z的联合分布；

2.在重建模型Ladder Net上加了一个横向bottleneck结构（就是一个卷积层），通过自编码器结构生成重建图像。

从实验结果来看，使用Openmax比softmax高出大约10%，使用分类＋重建比只使用分类高出大约10%，作者提出的DHRNet比LadderNet早CIFAR-10上高出大约6%-7%，在开放集上能够达到70%以上的F1-Score效果很可观。



总结：一个有意思的发现，虽然都是做UDA，但是这些论文当中的引用差别很大，一般引用的都是自己组里的文章，有点巧合。
